{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from utils import Utils\n",
    "from arcpyUtils import ArcpyUtils\n",
    "from gdalUtils import GdalUtils\n",
    "from landforms import Landforms\n",
    "from processDem import ProcessDem\n",
    "from rasterMasking import RasterMasking\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Align all rasters, including backscatter and higher resolution files to the 1-m DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= CONFIGURATION =================\n",
    "REEF_NAME = \"BayHarbor\"  # Name of the reef directory\n",
    "ABRV = \"BH\"\n",
    "BASE_DIR = fr\"C:\\Users\\ageglio\\Documents\\NLM_DataRelease\\Updated_DataRelease_Surfaces_NewProducts\"\n",
    "\n",
    "# List resolutions in priority order (first valid one found becomes the reference/snap raster) - also the subfolder names\n",
    "TARGET_RESOLUTIONS = [\"1m\", \"0.5m\", \"0.25m\"]\n",
    "\n",
    "# Define markers used in filenames\n",
    "DEM_MARKER = \"BY\"  # Bathymetry\n",
    "BS_MARKER = \"BS\"   # Backscatter\n",
    "\n",
    "PRODUCTS = [\"slope\", \"aspect\", \"roughness\", \"tpi\", \"tri\", \"hillshade\", \"shannon_index\"]\n",
    "\n",
    "DIVISIONS = 2 # Divide the height by this to run tile processing of DEM file, automatic overalap computed.\n",
    "# ================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment Code\n",
    "\n",
    "# --- 1. Identify Inputs ---\n",
    "REEF_DIR = os.path.join(BASE_DIR, REEF_NAME)\n",
    "input_dems = Utils.find_rasters(REEF_DIR, ABRV, TARGET_RESOLUTIONS, DEM_MARKER)\n",
    "input_bss = Utils.find_rasters(REEF_DIR, ABRV, TARGET_RESOLUTIONS, BS_MARKER)\n",
    "\n",
    "# Basic validation\n",
    "if not input_dems:\n",
    "    raise FileNotFoundError(f\"No DEMs found in {REEF_DIR} for resolutions {TARGET_RESOLUTIONS}\")\n",
    "\n",
    "print(f\"FOUND DEMS ({len(input_dems)}):\")\n",
    "print(\"\\n\".join([f\"  - {os.path.basename(f)}\" for f in input_dems]))\n",
    "\n",
    "if input_bss:\n",
    "    print(f\"FOUND BACKSCATTER ({len(input_bss)}):\")\n",
    "    print(\"\\n\".join([f\"  - {os.path.basename(f)}\" for f in input_bss]))\n",
    "else:\n",
    "    print(\"NO BACKSCATTER FILES FOUND. Proceeding with DEMs only.\")\n",
    "\n",
    "print(f\"PRODUCTS: {PRODUCTS}\")\n",
    "\n",
    "# --- 2. Combine for Processing ---\n",
    "# Combine lists. DEMs first ensures the highest res DEM is the primary snap raster\n",
    "input_rasters_list = input_dems + input_bss\n",
    "\n",
    "# --- 3. Create Intersection Mask and Align ---\n",
    "# This aligns everything to the first raster in the list (the highest priority DEM)\n",
    "intersection_mask, aligned_rasters_list = RasterMasking.return_valid_data_mask_intersection(input_rasters_list)\n",
    "# --- 4. Separate Outputs back into DEM and BS ---\n",
    "# Using case-insensitive check for robustness\n",
    "aligned_bss = [f for f in aligned_rasters_list if f\"_{BS_MARKER}_\".lower() in os.path.basename(f).lower()]\n",
    "aligned_dems = [f for f in aligned_rasters_list if f not in aligned_bss]\n",
    "\n",
    "# --- 5. Final Validation ---\n",
    "print(\"-\" * 30)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(f\"Aligned DEMs: {len(aligned_dems)}\")\n",
    "print(f\"Aligned BS:   {len(aligned_bss)}\")\n",
    "\n",
    "# Verify we didn't lose any DEMs during the intersection process\n",
    "if len(aligned_dems) != len(input_dems):\n",
    "    print(f\"WARNING: Input DEM count ({len(input_dems)}) matches Aligned DEM count ({len(aligned_dems)})? NO\")\n",
    "else:\n",
    "    print(\"Validation: Input and Aligned DEM counts match.\")\n",
    "\n",
    "# --- 6. Cleanup ---\n",
    "print(\"-\" * 30)\n",
    "print(\"STARTING CLEANUP\")\n",
    "\n",
    "# Collect all files involved (Inputs, Aligned Outputs, and the Mask)\n",
    "all_involved_files = input_rasters_list + aligned_rasters_list\n",
    "if intersection_mask:\n",
    "    all_involved_files.append(intersection_mask)\n",
    "\n",
    "# Extract unique directories using a set comprehension\n",
    "# This prevents trying to clean the same folder multiple times\n",
    "cleanup_dirs = {os.path.dirname(f) for f in all_involved_files if f and os.path.exists(os.path.dirname(f))}\n",
    "\n",
    "# Iterate and clean\n",
    "for directory in cleanup_dirs:\n",
    "    # Optional: Print where we are cleaning\n",
    "    Utils.remove_additional_files(directory=directory)\n",
    "\n",
    "print(\"Cleanup Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate derived DEM products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate terrain products of all of the dems and align the backscatter files\n",
    "for input_dem, input_bs in zip(aligned_dems, aligned_bss):\n",
    "    # Create an instance of the ProcessDEM class with the specified parameters\n",
    "    generateHabitatDerivates = ProcessDem(\n",
    "                                    input_dem=input_dem,\n",
    "                                    input_bs=input_bs,\n",
    "                                    binary_mask=intersection_mask,\n",
    "                                    products=PRODUCTS,\n",
    "                                    shannon_window=[3, 9, 21],\n",
    "                                    fill_method=\"IDW\",\n",
    "                                    fill_iterations=1,\n",
    "                                    divisions=DIVISIONS,  # Divide the height by this to run tile processing of DEM file, automatic overalap computed.\n",
    "                                    generate_boundary=True\n",
    "                                    )\n",
    "    # Process the DEM and generate the habitat derivatives\n",
    "    generateHabitatDerivates.process_dem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create geomorphons landforms using arcpy 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create original landforms from ArcGIS Pro\n",
    "filled_dems = [glob.glob(os.path.join(os.path.dirname(dem), \"filled\", f\"*{DEM_MARKER}*.tif\")) for dem in input_dems]\n",
    "filled_dems = [item for sublist in filled_dems for item in sublist]\n",
    "for filled_dem in filled_dems:\n",
    "    print(\"creating landforms for:\", os.path.basename(filled_dem))\n",
    "    landofrms_directory = Landforms(filled_dem).generate_landforms()\n",
    "    # Clean up additional files after processing\n",
    "    Utils.remove_additional_files(directory=landofrms_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you want to save the landforms classification histogram and metadata\n",
    "classes = \"10\"\n",
    "input_dem = filled_dems[0]\n",
    "raster_path = os.path.join(os.path.dirname(os.path.dirname(input_dem)), \"geomorphons\", Utils.sanitize_path_to_name(input_dem)+f\"_{classes}c.tif\")\n",
    "Landforms.analyze_geomorphon_data(raster_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tracklines to shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allowing the user to run all without executing the trackline portion\n",
    "assert 1==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../src\")\n",
    "from extents import GetExtents\n",
    "\n",
    "# Define the output folder path for shapefiles\n",
    "out_folder = \"..\\\\shapefiles\"\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "trackline_folder = r\"C:\\Users\\ageglio\\Documents\\NLM_DataRelease\\FINAL_DataRelease_Files_21-23\\BayHarborReef_2021 (1)\\BayHarborReef_2021\\Bay Harbor Reef_Tracklines\"\n",
    "print(\"folder path chosen: \", trackline_folder)\n",
    "\n",
    "## combine and convert tracklines to a shapefile\n",
    "# Removed threshold_seconds argument as it is no longer relevant for the file-based approach\n",
    "GetExtents.create_tracklines(trackline_folder, out_folder, utm_zone=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcpy3.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
